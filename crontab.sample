#----------------------------------------------------------------------------

# Refresh the list of service nodes that are not running from the BDII and GOCDB (downtime, not in prod, not monitored)
10,40 * * * * . /etc/profile; export VO_SUPPORT_TOOLS=$HOME/vo-support-tools; $VO_SUPPORT_TOOLS/service-status.py --vo biomed --pretty > /tmp/biomed/service-status-$$.txt; mv /tmp/biomed/service-status-$$.txt $HOME/public_html/biomed/service-status.txt

#----------------------------------------------------------------------------

# Scan of full SEs: see SE/scan-se/README

# Refresh the SE space availability reports every 30 min
*/30 * * * * $HOME/vo-support-tools/SE/show-se-space/run-biomed-reports.sh >> /tmp/biomed/show-se-space/show-se-space.log

# Monitor SEs: get the filling rate of all SEs at 3am every day
10 3 * * * . /etc/profile; export VO_SUPPORT_TOOLS=$HOME/vo-support-tools; $VO_SUPPORT_TOOLS/SE/monitor-se/run-collect-se-space.sh --vo biomed

#----------------------------------------------------------------------------
# Monitoring CEs
10 0,4,8,12,16,20 * * * . /etc/profile; export VO_SUPPORT_TOOLS=$HOME/vo-support-tools; $VO_SUPPORT_TOOLS/CE/monitor-ce/run-collect-ce-job-status.sh --vo biomed

# Find out all CEs with badly published number of jobs (with default numbers 4444...)
*/30 * * * * . /etc/profile; export VO_SUPPORT_TOOLS=$HOME/vo-support-tools; $VO_SUPPORT_TOOLS/CE/find-ce-4444.sh > /tmp/biomed/ce-4444-$$.txt; mv /tmp/biomed/ce-4444-$$.txt $HOME/public_html/biomed/ce-4444.txt

